{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn_som.som import SOM \n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a numpy array from a file\n",
    "clean_feature_array = np.load('cuttedImages.npy')\n",
    "# Transpose the array\n",
    "clean_feature_array = clean_feature_array.T\n",
    "print(clean_feature_array.shape)\n",
    "\n",
    "# Size of pixels \n",
    "sizPix = clean_feature_array.shape[1]\n",
    "\n",
    "print(sizPix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_feature_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate min and max values of clean_feature_array\n",
    "print(np.amin(clean_feature_array))\n",
    "print(np.amax(clean_feature_array))\n",
    "valMax = np.amax(clean_feature_array)\n",
    "valMin = np.amin(clean_feature_array)\n",
    "\n",
    "clean_feature_array_norm = np.zeros(clean_feature_array.shape)\n",
    "# Normalization by the minimum of each row \n",
    "#for i in range(clean_feature_array.shape[0]):\n",
    "  #  clean_feature_array_norm[i] = (clean_feature_array[i] - np.amin(clean_feature_array[i])) / (np.amax(clean_feature_array[i]) - np.amin(clean_feature_array[i]))\n",
    "# Normalization by the maximum of each row \n",
    "for i in range(clean_feature_array.shape[0]):\n",
    "    clean_feature_array_norm[i] = (clean_feature_array[i]) / (np.amax(clean_feature_array[i]))\n",
    "# Normalization by its minimum or maximum value \n",
    "#clean_feature_array_norm = (clean_feature_array / valMax )\n",
    "#clean_feature_array_norm = (clean_feature_array - valMin) /(valMax - valMin)\n",
    "#print(np.amin(clean_feature_array_norm))\n",
    "#print(np.amax(clean_feature_array_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_feature_array_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_feature_array_norm[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold  clean_feature_array_norm (you can do it with the not normalized array too)\n",
    "clean_feature_array_norm_th = clean_feature_array_norm.copy()\n",
    "rows_to_delete = []  # Keep track of rows to delete\n",
    "rows_to_maintain = []\n",
    "\n",
    "# sum all the intensities of each event\n",
    "for i in range(len(clean_feature_array_norm_th[:,0])):\n",
    "    if np.sum(clean_feature_array_norm_th[i,:]) > 600:\n",
    "        rows_to_delete.append(i)\n",
    "        print(\"Event to delete: \", i)\n",
    "    else:\n",
    "        rows_to_maintain.append(i)\n",
    "print(\"Number of events to delete: \", len(rows_to_delete))\n",
    "\n",
    "#new array with the rows to maintain\n",
    "clean_feature_array_norm_th = np.zeros((len(rows_to_maintain), len(clean_feature_array_norm[0,:])))\n",
    "#move all columns to be maintained using the list columns_to_maintain\n",
    "clean_feature_array_norm_th = clean_feature_array_norm[rows_to_maintain, :]\n",
    "print(\"Number of events:\", len(clean_feature_array_norm_th[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold  clean_feature_array (you can do it with the normalized array too)\n",
    "clean_feature_array_th = clean_feature_array.copy()\n",
    "rows_to_delete = []  # Keep track of rows to delete\n",
    "rows_to_maintain = []\n",
    "\n",
    "# sum all the intensities of each event\n",
    "for i in range(len(clean_feature_array_th[:,0])):\n",
    "    if np.sum(clean_feature_array_th[i,:]) > 60000:\n",
    "        rows_to_delete.append(i)\n",
    "        print(\"Event to delete: \", i)\n",
    "    else:\n",
    "        rows_to_maintain.append(i)\n",
    "print(\"Number of events to delete: \", len(rows_to_delete))\n",
    "\n",
    "#new array with the rows to maintain\n",
    "clean_feature_array_th = np.zeros((len(rows_to_maintain), len(clean_feature_array[0,:])))\n",
    "#move all columns to be maintained using the list columns_to_maintain\n",
    "clean_feature_array_th = clean_feature_array[rows_to_maintain, :]\n",
    "print(\"Number of events:\", len(clean_feature_array_th[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The som has NxN neurons \n",
    "# sizPix represents the number of features\n",
    "N=40\n",
    "som25 = SOM(m = N, n = N, dim = sizPix, max_iter=19000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs is the number of iterations for the training\n",
    "#som25.fit(clean_feature_array_norm, epochs=200)\n",
    "#som25.fit(clean_feature_array_norm, epochs=10)\n",
    "som25.fit(clean_feature_array_norm_th, epochs=300)\n",
    "#som25.fit(clean_feature_array, epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights represent the position of the neurons in \n",
    "# the feature space\n",
    "weights_ini = som25.weights\n",
    "print(weights_ini.shape)\n",
    "# reshape first index from 400 to 20x20 two indices\n",
    "# From 1D array to 3D array\n",
    "weights = weights_ini.reshape(N,N,sizPix)\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that weigths_ini and weights are the same\n",
    "print(weights_ini[N+N+2, 0])\n",
    "print(weights[2, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pix_x.npy and pix_y.npy\n",
    "pix_x = np.load('pix_x.npy')\n",
    "pix_y = np.load('pix_y.npy')\n",
    "print(pix_x.shape)\n",
    "print(pix_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the lenght of the pixels by a factor of 2 by making the mean of every 2 pixels\n",
    "reduction_factor = 2\n",
    "counter = 0\n",
    "new_pix_x = np.zeros(len(pix_x) // reduction_factor)\n",
    "new_pix_y = np.zeros(len(pix_y) // reduction_factor)    \n",
    "print(new_pix_x.shape, new_pix_y.shape)\n",
    "\n",
    "# Loop over the pixel's positions and make the mean of every reduction_factor pixels\n",
    "for i in range(len(new_pix_x)):\n",
    "    if i <= (len(pix_x) // reduction_factor) - 1:\n",
    "        new_pix_x[i] = np.mean((pix_x[i * reduction_factor], pix_x[(i * reduction_factor) + 1]))\n",
    "        new_pix_y[i] = np.mean((pix_y[i * reduction_factor], pix_y[(i * reduction_factor) + 1]))\n",
    "    else:\n",
    "        new_pix_x[i] = pix_x[i]\n",
    "        new_pix_y[i] = pix_y[i]\n",
    "\n",
    "print(new_pix_x.shape, new_pix_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D list of tuples\n",
    "vecs = [(new_pix_x[i], new_pix_y[i]) for i in range(len(new_pix_x))]\n",
    "#print(len(vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate max_x and min_x, print\n",
    "max_x = max(new_pix_x)\n",
    "min_x = min(new_pix_x)\n",
    "print(f\"max_x: {max_x}, min_x: {min_x}\")\n",
    "# Calculate max_y and min_y, print\n",
    "max_y = max(new_pix_y)\n",
    "min_y = min(new_pix_y)\n",
    "print(f\"max_y: {max_y}, min_y: {min_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the weights of a node\n",
    "firstNodeData = clean_feature_array_th[900] # weights[1,1,:]\n",
    "# scatter plot, pix_x, pix_y, s = 1, c = firstNodeData. big circles\n",
    "plt.scatter(new_pix_x, new_pix_y, s = 55, c = firstNodeData)\n",
    "\n",
    "# x and y limits for the plot\n",
    "plt.xlim(min_x, max_x)\n",
    "plt.ylim(min_x, max_x)\n",
    "# square size\n",
    "plt.gcf().set_size_inches(5,5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do a different plot. go through a MxM matrix, select the color of the nearest node\n",
    "# separate the storage of nearest node index and then color assignment\n",
    "M = 50\n",
    "matrixI = np.zeros((M,M), dtype = int)\n",
    "for i in range(M):\n",
    "    for j in range(M):\n",
    "        x = min_x + (max_x - min_x)*i/M\n",
    "        y = min_y + (max_y - min_y)*j/M\n",
    "        # find the nearest node from vecs\n",
    "        # vecs is a list of tuples\n",
    "        minDist = 1000000\n",
    "        for k in range(len(vecs)):\n",
    "            # Euclidean distance between position (x,y) and vecs[k]\n",
    "            dist = (vecs[k][0]-x)**2 + (vecs[k][1]-y)**2\n",
    "            if dist < minDist:\n",
    "                minDist = dist\n",
    "                matrixI[i,j] = k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate matrixC\n",
    "matrixC = np.zeros((M,M))\n",
    "for i in range(M):\n",
    "    for j in range(M):\n",
    "        matrixC[i,j] = firstNodeData[matrixI[i,j]]\n",
    "plt.imshow(matrixC)\n",
    "# colorbar\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "# now matrixC with a different node\n",
    "secondNodeData = clean_feature_array_th[1329]# weights[2,2,:]\n",
    "matrixC = np.zeros((M,M))\n",
    "for i in range(M):\n",
    "    for j in range(M):\n",
    "        matrixC[i,j] = secondNodeData[matrixI[i,j]]\n",
    "plt.imshow(matrixC)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a super matrix for all the nodes to store in a single 2D image\n",
    "# N is the number of nodes in the SOM\n",
    "# M is the size of the matrix for each node\n",
    "# Dimensions of the super matrix\n",
    "widthPixels = M*N+(N-1) # Separation of 1 pix between each node\n",
    "heightPixels = M*N+(N-1) # same\n",
    "superMatrix = np.zeros((widthPixels, heightPixels))\n",
    "# Iterate over the nodes\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        # Fill with the data from the node\n",
    "        nodeData = weights[i,j,:]\n",
    "        for k in range(M):\n",
    "            for l in range(M):\n",
    "                # Fill with data of the nearest node\n",
    "                superMatrix[i*M+i+k,j*M+j+l] = nodeData[matrixI[k,l]]\n",
    "borderValue = np.max(superMatrix)\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        # Set the borders\n",
    "        superMatrix[i*M+i:i*M+i+M,j*M+j] = borderValue\n",
    "        superMatrix[i*M+i,j*M+j:j*M+j+M] = borderValue\n",
    "print(np.min(superMatrix))\n",
    "\n",
    "superMatrix2=np.clip(superMatrix, 1,8)\n",
    "# Linear case \n",
    "#plt.imshow(superMatrix2)\n",
    "# Logarithmic scale\n",
    "plt.imshow(np.log(superMatrix2))\n",
    "# Make it bigger\n",
    "plt.gcf().set_size_inches(11,11)\n",
    "# Add colorbar\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a super matrix for all the nodes to store in a single 2D image\n",
    "# N is the number of nodes in the SOM\n",
    "# M is the size of the matrix for each node\n",
    "# Dimensions of the super matrix\n",
    "widthPixels = M*N+(N-1) # Separation of 1 pix between each node\n",
    "heightPixels = M*N+(N-1) # same\n",
    "superMatrix = np.zeros((widthPixels, heightPixels))\n",
    "# Iterate over the nodes\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        # Fill with the data from the node\n",
    "        nodeData = weights[i,j,:]\n",
    "        for k in range(M):\n",
    "            for l in range(M):\n",
    "                # Fill with data of the nearest node\n",
    "                superMatrix[i*M+i+k,j*M+j+l] = nodeData[matrixI[k,l]]\n",
    "borderValue = np.max(superMatrix)\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        # Set the borders\n",
    "        superMatrix[i*M+i:i*M+i+M,j*M+j] = borderValue\n",
    "        superMatrix[i*M+i,j*M+j:j*M+j+M] = borderValue\n",
    "print(np.min(superMatrix))\n",
    "\n",
    "superMatrix2=np.clip(superMatrix, 1,10)\n",
    "# Logarithmic scale\n",
    "plt.imshow(np.sqrt(superMatrix2))\n",
    "# Make it bigger\n",
    "plt.gcf().set_size_inches(10,10)\n",
    "# Add colorbar\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
